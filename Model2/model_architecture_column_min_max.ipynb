{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 모델의 디자인입니다 \n",
    "# 실제 활용시에는 여기에 작성된 모델링 코드로 돌리지 마시고 \n",
    "# 'Final_model_dl.h5' load 후 돌려주세요 \n",
    "# 왜냐면 돌릴 때마다 역전파로 인해 가중치가 미묘하게 달라지면서 성능 결과가 달르게 나옵니다.\n",
    "# 현재 Final_model_dl.h5이 최적화된 파일이라서\n",
    "# 이 파일을 로드해서 사용해주세요 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model 아키텍쳐 \n",
    "# 덕지 덕지 붙었던 하이퍼파라미터 튜닝등을 다시 덜어낸 후 성능이 훨씬 올라간 마지막 모델\n",
    "# 검증은 3way 로 나누지 않았고, \n",
    "# .fit() 메소드에 있는 validation_split=0.1 을 이용하여 하였다.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed_value = 4\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Assuming df is your DataFrame containing the data\n",
    "# and 'target_class' is the binary classification target variable\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = df.drop('target_class', axis=1)\n",
    "y = df['target_class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the scaler on the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the trained scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build the deep learning model with more hidden layers\n",
    "final_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "final_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the scaled training data\n",
    "history = final_model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=0)\n",
    "\n",
    "# Make predictions on the scaled test data\n",
    "y_pred_dl = (final_model.predict(X_test_scaled) > 0.5).astype(int).flatten()\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dl = accuracy_score(y_test, y_pred_dl)\n",
    "print(\"Deep Learning Accuracy:\", accuracy_dl)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Deep Learning Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dl))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix_dl = confusion_matrix(y_test, y_pred_dl)\n",
    "print(\"Deep Learning Confusion Matrix:\")\n",
    "print(conf_matrix_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # app.py\n",
    "# import pickle\n",
    "# import numpy as np\n",
    "# from tensorflow.keras.models import load_model\n",
    "# model = load_model('Final_model_dl.h5')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"binary_classification_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum values in each column:\n",
      " Mean of the integrated profile                   5.812500\n",
      " Standard deviation of the integrated profile    24.772042\n",
      " Excess kurtosis of the integrated profile       -1.876011\n",
      " Skewness of the integrated profile              -1.791886\n",
      " Mean of the DM-SNR curve                         0.213211\n",
      " Standard deviation of the DM-SNR curve           7.370432\n",
      " Excess kurtosis of the DM-SNR curve             -3.139270\n",
      " Skewness of the DM-SNR curve                    -1.976976\n",
      "target_class                                      0.000000\n",
      "dtype: float64\n",
      "\n",
      "Maximum values in each column:\n",
      " Mean of the integrated profile                   192.617188\n",
      " Standard deviation of the integrated profile      98.778911\n",
      " Excess kurtosis of the integrated profile          8.069522\n",
      " Skewness of the integrated profile                68.101622\n",
      " Mean of the DM-SNR curve                         223.392141\n",
      " Standard deviation of the DM-SNR curve           110.642211\n",
      " Excess kurtosis of the DM-SNR curve               34.539844\n",
      " Skewness of the DM-SNR curve                    1191.000837\n",
      "target_class                                        1.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "min_values = df.apply(min)\n",
    "max_values = df.apply(max)\n",
    "\n",
    "print(\"Minimum values in each column:\")\n",
    "print(min_values)\n",
    "\n",
    "print(\"\\nMaximum values in each column:\")\n",
    "print(max_values)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code_final_p1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
